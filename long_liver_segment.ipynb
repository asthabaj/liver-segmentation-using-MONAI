{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae84af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from monai.config import print_config\n",
    "from monai.transforms import SpatialPadd\n",
    "from monai.transforms import Lambdad\n",
    "from monai.transforms import RandCropByLabelClassesd\n",
    "from monai.transforms import ScaleIntensityRanged\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd,\n",
    "    Orientationd, Spacingd, \n",
    "    ScaleIntensityd, RandSpatialCropd, ToTensord,\n",
    "    Activations, AsDiscrete\n",
    ")\n",
    "from monai.networks.nets import UNet \n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric, MeanIoU\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import Activations, AsDiscrete, Compose\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d748497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "set_determinism(seed=11)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88cc7b6",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832f66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"D:/monai-project/asa/data\"\n",
    "image_files = sorted(glob.glob(os.path.join(data_dir, \"imagesTr\", \"liver_*.nii.gz\")))\n",
    "label_files = sorted(glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610c4235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed8d10",
   "metadata": {},
   "source": [
    "# Split data (80% train, 20% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab784d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    image_files, label_files, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef58a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 104 27 27\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images), len(train_labels), len(test_images), len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1a534",
   "metadata": {},
   "source": [
    "# Create data dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b78a4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [{\"image\": img, \"label\": lbl} for img, lbl in zip(train_images, train_labels)]\n",
    "test_files = [{\"image\": img, \"label\": lbl} for img, lbl in zip(test_images, test_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b792ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_label(x):\n",
    "    return (x == 1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69765bef",
   "metadata": {},
   "source": [
    "# Transforms & Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5541786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = (128, 128, 64)\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    Spacingd(keys=[\"image\", \"label\"], pixdim=(1,1,3), mode=(\"bilinear\", \"nearest\")),\n",
    "    ScaleIntensityRanged(\n",
    "        keys=\"image\",\n",
    "        a_min=-200, a_max=200,\n",
    "        b_min=0.0, b_max=1.0,\n",
    "        clip=True\n",
    "    ),\n",
    "    SpatialPadd(keys=[\"image\", \"label\"], spatial_size=crop_size),\n",
    "    # Replace this:\n",
    "    # RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=crop_size, random_size=False),\n",
    "    # With this:\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=crop_size,\n",
    "        num_classes=2,\n",
    "        num_samples=1,\n",
    "    ),\n",
    "    Lambdad(keys=\"label\", func=binarize_label),\n",
    "    ToTensord(keys=[\"image\", \"label\"]),\n",
    "])\n",
    "test_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    Spacingd(keys=[\"image\", \"label\"], pixdim=(1,1,3), mode=(\"bilinear\", \"nearest\")),\n",
    "    ScaleIntensityRanged(\n",
    "        keys=\"image\",\n",
    "        a_min=-200, a_max=200,\n",
    "        b_min=0.0, b_max=1.0,\n",
    "        clip=True\n",
    "    ),\n",
    "    SpatialPadd(keys=[\"image\", \"label\"], spatial_size=crop_size),  # <--- Add this line\n",
    "    Lambdad(keys=\"label\", func=binarize_label),\n",
    "    ToTensord(keys=[\"image\", \"label\"]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617e76a",
   "metadata": {},
   "source": [
    "# Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa6e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "test_ds = Dataset(data=test_files, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb02156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c18237",
   "metadata": {},
   "source": [
    "# Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31e98ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247b7c06",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4009e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,  # 2 classes: background and liver\n",
    "    channels=(8, 16, 32, 64, 128),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceLoss(softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "iou_metric = MeanIoU(include_background=True, reduction=\"mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f1d047",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1c91c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trans = Compose([Activations(softmax=True), AsDiscrete(argmax=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "959bce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     sample = train_ds[44][0]\n",
    "#     print(np.unique(sample[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ddaec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_epochs = 75\n",
    "# train_losses = []\n",
    "# val_dice_scores = []\n",
    "# val_iou_scores = []\n",
    "\n",
    "# for epoch in range(max_epochs):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for batch_data in train_loader:\n",
    "#         inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "#         labels = labels.squeeze(1).long()   # shape (B, H, W, D)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)  # Raw logits, shape (B, 2, H, W, D)\n",
    "#         # --- One-hot encode for loss ---\n",
    "#         labels_onehot = torch.nn.functional.one_hot(labels, num_classes=2)  # [B, H, W, D, 2]\n",
    "#         labels_onehot = labels_onehot.permute(0, 4, 1, 2, 3).float()        # [B, 2, H, W, D]\n",
    "#         loss = loss_function(outputs, labels_onehot)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "    \n",
    "#     epoch_loss /= len(train_loader)\n",
    "#     train_losses.append(epoch_loss)\n",
    "    \n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     dice_vals, iou_vals = [], []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for test_data in test_loader:\n",
    "#             inputs, labels = test_data[\"image\"].to(device), test_data[\"label\"].to(device)\n",
    "#             labels = labels.squeeze(1).long()\n",
    "#             outputs = sliding_window_inference(\n",
    "#                 inputs, \n",
    "#                 roi_size=crop_size, \n",
    "#                 sw_batch_size=4,\n",
    "#                 predictor=model,\n",
    "#             )\n",
    "#             # For metrics, use class indices (not one-hot)\n",
    "#             dice_metric(y_pred=outputs, y=labels)\n",
    "#             iou_metric(y_pred=outputs, y=labels)\n",
    "#             dice_vals.append(dice_metric.aggregate().item())\n",
    "#             iou_vals.append(iou_metric.aggregate().item())\n",
    "#             dice_metric.reset()\n",
    "#             iou_metric.reset()\n",
    "    \n",
    "#     avg_dice = np.mean(dice_vals)\n",
    "#     avg_iou = np.mean(iou_vals)\n",
    "#     val_dice_scores.append(avg_dice)\n",
    "#     val_iou_scores.append(avg_iou)\n",
    "    \n",
    "#     print(f\"Epoch {epoch+1}/{max_epochs}\")\n",
    "#     print(f\"Train Loss: {epoch_loss:.4f}\")\n",
    "#     print(f\"Val Dice: {avg_dice:.4f}, Jaccard: {avg_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1/50 ---\n",
      "  Batch 5/52 - Loss: 0.4011\n",
      "  Batch 10/52 - Loss: 0.4894\n",
      "  Batch 15/52 - Loss: 0.5334\n",
      "  Batch 20/52 - Loss: 0.6202\n",
      "  Batch 25/52 - Loss: 0.4319\n",
      "  Batch 30/52 - Loss: 0.2848\n",
      "  Batch 35/52 - Loss: 0.4460\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "train_losses = []\n",
    "val_dice_scores = []\n",
    "val_iou_scores = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{max_epochs} ---\")  # Start of epoch\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "        labels = labels.squeeze(1).long()   # shape (B, H, W, D)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # Raw logits, shape (B, 2, H, W, D)\n",
    "        \n",
    "        # --- One-hot encode for loss ---\n",
    "        labels_onehot = torch.nn.functional.one_hot(labels, num_classes=2)  # [B, H, W, D, 2]\n",
    "        labels_onehot = labels_onehot.permute(0, 4, 1, 2, 3).float()        # [B, 2, H, W, D]\n",
    "        loss = loss_function(outputs, labels_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            print(f\"  Batch {batch_idx+1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    dice_vals, iou_vals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for test_data in test_loader:\n",
    "            inputs, labels = test_data[\"image\"].to(device), test_data[\"label\"].to(device)\n",
    "            labels = labels.squeeze(1).long()\n",
    "            outputs = sliding_window_inference(\n",
    "                inputs, \n",
    "                roi_size=crop_size, \n",
    "                sw_batch_size=4,\n",
    "                predictor=model,\n",
    "            )\n",
    "            # For metrics, use class indices (not one-hot)\n",
    "            dice_metric(y_pred=outputs, y=labels)\n",
    "            iou_metric(y_pred=outputs, y=labels)\n",
    "            dice_vals.append(dice_metric.aggregate().item())\n",
    "            iou_vals.append(iou_metric.aggregate().item())\n",
    "            dice_metric.reset()\n",
    "            iou_metric.reset()\n",
    "    \n",
    "    avg_dice = np.mean(dice_vals)\n",
    "    avg_iou = np.mean(iou_vals)\n",
    "    val_dice_scores.append(avg_dice)\n",
    "    val_iou_scores.append(avg_iou)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} Results:\")\n",
    "    print(f\"  Train Loss: {epoch_loss:.4f}\")\n",
    "    print(f\"  Val Dice:  {avg_dice:.4f}\")\n",
    "    print(f\"  Jaccard:   {avg_iou:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), f\"checkpoint_epoch{epoch+1}.pth\")\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cf099",
   "metadata": {},
   "source": [
    "# Visualization of loss and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(val_dice_scores, label=\"Dice\")\n",
    "plt.plot(val_iou_scores, label=\"Jaccard\")\n",
    "plt.legend()\n",
    "plt.savefig(\"training_metrics.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad86414",
   "metadata": {},
   "source": [
    "# Visualize test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff64d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_data = next(iter(test_loader))\n",
    "    input_img = test_data[\"image\"].to(device)\n",
    "    label_img = test_data[\"label\"].cpu().numpy()[0, 0]\n",
    "    \n",
    "    # Get prediction\n",
    "    pred = sliding_window_inference(\n",
    "        input_img, \n",
    "        roi_size=crop_size, \n",
    "        sw_batch_size=4,\n",
    "        predictor=model,\n",
    "    )\n",
    "    pred = post_trans(pred)[0].cpu().numpy()  # shape: (H, W, D)\n",
    "    \n",
    "    # Display middle slices\n",
    "    slice_idx = pred.shape[2] // 2\n",
    "    input_slice = input_img[0, 0, :, :, slice_idx].cpu().numpy()\n",
    "    pred_slice = pred[:, :, slice_idx]\n",
    "    label_slice = label_img[:, :, slice_idx]\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(input_slice, cmap=\"gray\")\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(pred_slice, cmap=\"jet\", vmin=0, vmax=1)\n",
    "    plt.title(\"Prediction (0=bg, 1=liver)\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(label_slice, cmap=\"jet\", vmin=0, vmax=1)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.savefig(\"segmentation_comparison.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03f07e",
   "metadata": {},
   "source": [
    "# Save model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91d88ff",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), \"liver_seg_unet_2class.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
